{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "M2b5k3x1o967",
    "outputId": "cd25a30d-692e-46af-a3d4-13d46956a920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-10e61ff1-b7cd-4d6b-b250-c14dcbe9aca2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_C</th>\n",
       "      <th>BMI01</th>\n",
       "      <th>ETHANL03</th>\n",
       "      <th>CIGT01</th>\n",
       "      <th>MOVE</th>\n",
       "      <th>P_CARB</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>DFIB</th>\n",
       "      <th>P_PROT</th>\n",
       "      <th>P_SFAT</th>\n",
       "      <th>...</th>\n",
       "      <th>ANTA01</th>\n",
       "      <th>ANTA07A</th>\n",
       "      <th>ANTA07B</th>\n",
       "      <th>ECGMA31</th>\n",
       "      <th>HMTA03</th>\n",
       "      <th>APASIU01</th>\n",
       "      <th>APBSIU01</th>\n",
       "      <th>LIPA08</th>\n",
       "      <th>CHMA09</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28.767562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>55.763035</td>\n",
       "      <td>271.47</td>\n",
       "      <td>15.51</td>\n",
       "      <td>20.085680</td>\n",
       "      <td>9.698284</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34.645233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.250</td>\n",
       "      <td>46.258407</td>\n",
       "      <td>335.55</td>\n",
       "      <td>9.92</td>\n",
       "      <td>18.071302</td>\n",
       "      <td>14.855120</td>\n",
       "      <td>...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28.392191</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.250</td>\n",
       "      <td>51.184492</td>\n",
       "      <td>358.20</td>\n",
       "      <td>24.20</td>\n",
       "      <td>22.774525</td>\n",
       "      <td>9.353566</td>\n",
       "      <td>...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>22.038567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.750</td>\n",
       "      <td>48.461187</td>\n",
       "      <td>220.87</td>\n",
       "      <td>12.62</td>\n",
       "      <td>20.222597</td>\n",
       "      <td>13.905987</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30.452441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.125</td>\n",
       "      <td>53.584911</td>\n",
       "      <td>106.73</td>\n",
       "      <td>24.73</td>\n",
       "      <td>16.452840</td>\n",
       "      <td>11.733608</td>\n",
       "      <td>...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10e61ff1-b7cd-4d6b-b250-c14dcbe9aca2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-10e61ff1-b7cd-4d6b-b250-c14dcbe9aca2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-10e61ff1-b7cd-4d6b-b250-c14dcbe9aca2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   ID_C      BMI01  ETHANL03  CIGT01   MOVE     P_CARB    CHOL   DFIB  \\\n",
       "0     1  28.767562       0.0     3.0  5.000  55.763035  271.47  15.51   \n",
       "1     2  34.645233       0.0     3.0  7.250  46.258407  335.55   9.92   \n",
       "2     3  28.392191      41.0     2.0  6.250  51.184492  358.20  24.20   \n",
       "3     4  22.038567       0.0     3.0  5.750  48.461187  220.87  12.62   \n",
       "4     5  30.452441       0.0     2.0  9.125  53.584911  106.73  24.73   \n",
       "\n",
       "      P_PROT     P_SFAT  ...  ANTA01  ANTA07A  ANTA07B  ECGMA31  HMTA03  \\\n",
       "0  20.085680   9.698284  ...   159.0    102.0    112.0     69.0     4.6   \n",
       "1  18.071302  14.855120  ...   164.0    106.0    117.0     73.0     7.6   \n",
       "2  22.774525   9.353566  ...   164.0     95.0    105.0     73.0     7.4   \n",
       "3  20.222597  13.905987  ...   165.0     73.0    103.0     56.0     5.9   \n",
       "4  16.452840  11.733608  ...   163.0    106.0    109.0     63.0     3.7   \n",
       "\n",
       "   APASIU01  APBSIU01  LIPA08  CHMA09  CLASS  \n",
       "0    1450.0    1700.0     8.0     1.1      0  \n",
       "1       NaN       NaN     NaN     1.0      0  \n",
       "2    1500.0    1270.0    12.0     1.1      0  \n",
       "3    2190.0     770.0    32.0     1.0      0  \n",
       "4    1310.0     890.0   248.0     1.0      0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Drive helper and mount\n",
    "# from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# load data\n",
    "# ASD_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/ASD_gene_labeled.csv')\n",
    "# ASD_data.head() \n",
    "# fatchd_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/FATCHD/FATCHD.csv')\n",
    "# fatchd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW_pzrICO7pa"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "# creating X, Y train for cv and data preprocessing\n",
    "Y = fatchd_data['CLASS']\n",
    "X = fatchd_data\n",
    "X.drop(['ID_C', 'CLASS'], axis=1, inplace=True)\n",
    "# dealing with na values\n",
    "# X = X.fillna(0)\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "X = pd.DataFrame(imputer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Bd9rzSHfdzP"
   },
   "outputs": [],
   "source": [
    "# Adaptive SMOTE\n",
    "import math\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from operator import itemgetter, attrgetter\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from sklearn.decomposition import PCA\n",
    "class Adaptive_Smote:\n",
    "    def __init__(self,samples, N = 1, k = 5):\n",
    "        self.n_samples,self.n_attrs=samples.shape\n",
    "        self.N=N\n",
    "        self.k=k\n",
    "        self.samples=samples\n",
    "        self.newindex=0\n",
    "\n",
    "    def over_sampling(self):\n",
    "      N = self.N\n",
    "      self.synthetic = np.zeros((self.n_samples * N, self.n_attrs))\n",
    "      neighbors = NearestNeighbors(n_neighbors=self.k).fit(self.samples)\n",
    "      for i in range(len(self.samples)):\n",
    "        nnarray = neighbors.kneighbors(self.samples.iloc[[i]].values.reshape((1,-1)),return_distance = False)[0]  #Finds the K-neighbors of a point.\n",
    "        nnarray = np.delete(nnarray, 0)\n",
    "        adaptive_nnarray = self.neighborhood_selection(i, nnarray) \n",
    "        if adaptive_nnarray != []:\n",
    "          self._populate(N, i, adaptive_nnarray)\n",
    "      return self.synthetic\n",
    "\n",
    "    # neighborhood selection algorithm \n",
    "    def neighborhood_selection(self, i, nnarray):\n",
    "      visible_nnarray = []    \t\n",
    "      for j in range(len(nnarray)):\n",
    "        ck_nnarray = np.delete(nnarray, j)\n",
    "        ck = 0\n",
    "        for z in ck_nnarray:\n",
    "          inner_pro = np.inner((self.samples.iloc[[i]] - self.samples.iloc[z]), self.samples.iloc[nnarray[j]] - self.samples.iloc[z])\n",
    "          if inner_pro >= 0:\n",
    "            ck += 1\n",
    "          else:\n",
    "            ck += 0\n",
    "        if ck == len(ck_nnarray):\n",
    "          visible_nnarray.append(nnarray[j])   \n",
    "      return visible_nnarray\n",
    "\n",
    "      # for each minority class sample i ,choose N of the k nearest neighbors and generate N synthetic samples.\n",
    "    def _populate(self,N,i,nnarray):\n",
    "      for j in range(N): \n",
    "        nn = random.randint(0,len(nnarray)-1)  #include end\n",
    "        for attr in range(0, self.n_attrs):\n",
    "          dif = self.samples.iloc[nnarray[nn]][attr]-self.samples.iloc[[i]][attr]\n",
    "          gap = random.random()\n",
    "          self.synthetic[self.newindex][attr] = self.samples.iloc[[i]][attr] + gap*dif\n",
    "        self.newindex += 1\n",
    "        # print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBY4VZEpr3hX"
   },
   "outputs": [],
   "source": [
    "# Inspection Classifiers\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def inspection_classifier(majority_X, majority_y, min_data, smote_data, threshold):\n",
    "  # training inspection classifiers\n",
    "  num_removed_data = 0\n",
    "  n = math.floor(len(majority_X)/len(min_data))\n",
    "  split_X = np.array_split(majority_X, n)\n",
    "  split_y = np.array_split(majority_y, n)\n",
    "  min_y = pd.Series([1 for i in range(len(min_data))])\n",
    "  clf_lst = []\n",
    "  for i in range (0, n):\n",
    "    df_split_X = pd.DataFrame(split_X[i])\n",
    "    new_ad_cols = {x: y for x, y in zip(min_data, df_split_X.columns)}\n",
    "    combined_x = df_split_X.append(min_data.rename(columns=new_ad_cols))\n",
    "    combined_y = split_y[i].append(min_y)\n",
    "    rf = RandomForestClassifier(random_state=0)\n",
    "    rf.fit(combined_x, combined_y)\n",
    "    clf_lst.append(rf)\n",
    "\n",
    "  # inspection part\n",
    "  df_smote = pd.DataFrame(smote_data)\n",
    "  drop_index = []\n",
    "  for j in range(0, len(smote_data)): \n",
    "    score = 0\n",
    "    for clf in clf_lst:\n",
    "      if clf.predict(np.array(df_smote.iloc[j]).reshape(1, -1))[0] == 1:\n",
    "        score += 1\n",
    "    # remove\n",
    "    if score/len(clf_lst) < threshold:\n",
    "      drop_index.append(j)\n",
    "      num_removed_data += 1\n",
    "  df_smote.drop(df_smote.index[drop_index], inplace =True)    \n",
    "  # print(\"# of removed data:\", num_removed_data)\n",
    "  return df_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7_eI18_gKz6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "def score_report_manual(clf, X_test, y_test, y_pred):\n",
    "  cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "  tp = cf_matrix[1][1]\n",
    "  if tp == 0:\n",
    "    tp += 1\n",
    "  pr = tp/(tp + cf_matrix[1][0])\n",
    "  rc = tp/(tp + cf_matrix[0][1])\n",
    "  f_1 = (2 * pr * rc)/(pr + rc)\n",
    "  # y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "  y_pred_proba = (clf.predict_proba(X_test)[:, 1] > 0.5).astype('float')\n",
    "  precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "  f_score = (2 * precision * recall) / (precision + recall)\n",
    "  # index = np.argmax(f_score)\n",
    "  index = np.nanargmax(f_score)\n",
    "  thresholdOpt = round(thresholds[index], ndigits = 4)\n",
    "  fscoreOpt = round(f_score[index], ndigits = 4)\n",
    "  fscoreOpt2 = round(f_score[index], ndigits = 4)\n",
    "  recallOpt = round(recall[index], ndigits = 4)\n",
    "  precisionOpt = round(precision[index], ndigits = 4)\n",
    "  print('Best Threshold: {} with F-Score: {}'.format(thresholdOpt, fscoreOpt))\n",
    "  print('Recall: {}, Precision: {}'.format(recallOpt, precisionOpt))\n",
    "  auc = metrics.auc(recall, precision)\n",
    "  return precisionOpt, recallOpt, fscoreOpt, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cx6PCfAzyiS2",
    "outputId": "d940d0af-7b42-43e9-bf6d-8afc4c7f86ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.75 n: [13, 0.5] k: [75, 20] Threshold: 0.5 ratio: 0.05\n",
      "82\n",
      "Best Threshold: 1.0 with F-Score: 0.2712\n",
      "Recall: 0.237, Precision: 0.3168\n",
      "For fold 1:\n",
      "Precision 0.3168\n",
      "Recall 0.237\n",
      "F1 Score 0.2712\n",
      "Accuracy 0.9201856148491879\n",
      "81\n",
      "Best Threshold: 1.0 with F-Score: 0.2097\n",
      "Recall: 0.2, Precision: 0.2205\n",
      "For fold 2:\n",
      "Precision 0.2205\n",
      "Recall 0.2\n",
      "F1 Score 0.2097\n",
      "Accuracy 0.9020881670533643\n",
      "83\n",
      "Best Threshold: 1.0 with F-Score: 0.2311\n",
      "Recall: 0.2283, Precision: 0.2339\n",
      "For fold 3:\n",
      "Precision 0.2339\n",
      "Recall 0.2283\n",
      "F1 Score 0.2311\n",
      "Accuracy 0.9104408352668213\n",
      "83\n",
      "Best Threshold: 1.0 with F-Score: 0.2682\n",
      "Recall: 0.28, Precision: 0.2574\n",
      "For fold 4:\n",
      "Precision 0.2574\n",
      "Recall 0.28\n",
      "F1 Score 0.2682\n",
      "Accuracy 0.9113689095127611\n",
      "80\n",
      "Best Threshold: 1.0 with F-Score: 0.2662\n",
      "Recall: 0.2333, Precision: 0.3097\n",
      "For fold 5:\n",
      "Precision 0.3097\n",
      "Recall 0.2333\n",
      "F1 Score 0.2662\n",
      "Accuracy 0.9103992571959145\n",
      "average_precision 0.26765999999999995\n",
      "average_recall 0.23572\n",
      "average_f1 0.24928\n",
      "average_auc 0.27573753775658094\n",
      "average_accuracy 0.9108965567756098\n",
      "stdev_pr 0.04373548902207451\n",
      "stdev_rc 0.028719279238866708\n",
      "stdev_f1 0.027485578036490335\n",
      "stdev_acc 0.006413899661420886\n",
      "--------------------------------------------------\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "# A SMOTE (proposed method)\n",
    "# Adaptive SMOTE with inspection\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import statistics\n",
    "from sklearn.metrics import accuracy_score\n",
    "random.seed(10)\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state=0)\n",
    "for p in [0.75]:\n",
    "  for K in [[75,20]]:\n",
    "    for n in [[13,0.5]]:\n",
    "      acc_lst = []\n",
    "      f1 = []\n",
    "      precision_lst = []\n",
    "      recall_lst = []\n",
    "      auc_lst = []\n",
    "      len_df_syn = []\n",
    "      len_df_maj = []\n",
    "      print('p:', p,'n:', n, 'k:', K, 'Threshold: 0.5', \"ratio: 0.05\")\n",
    "      for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        # Data setting before SMOTE\n",
    "        X_4 = X.iloc[train_index.tolist()] \n",
    "        y_4 = Y.iloc[train_index.tolist()] \n",
    "        X_test_4 = X.iloc[test_index.tolist()]\n",
    "        y_test_4 = Y.iloc[test_index.tolist()]\n",
    "        train_combined = np.c_[X_4, y_4]\n",
    "        maj_x = train_combined[train_combined[:,37] == 0]\n",
    "        maj_x = np.delete(maj_x, 37, 1)\n",
    "        maj_y = pd.Series([0 for i in range(len(maj_x))])\n",
    "        df_maj_x1 = pd.DataFrame(maj_x)\n",
    "        minority_data = train_combined[train_combined[:,37] == 1][0:math.ceil(p*len(train_combined[train_combined[:,37] == 1]))]\n",
    "        minority_data = np.delete(minority_data, 37, 1)\n",
    "        df_min_data = pd.DataFrame(minority_data)\n",
    "        df_maj_x = df_maj_x1\n",
    "        min_y = pd.Series([1 for i in range(len(df_min_data))])\n",
    "        if math.ceil(K[1]/100*len(df_min_data)) < 1:\n",
    "          K_used = K[0]\n",
    "        else:\n",
    "          K_used = math.ceil(K[1]/100*len(df_min_data))\n",
    "\n",
    "        ########################################################## IMPLEMENTATION ##########################################################################\n",
    "        adaptive_smote = Adaptive_Smote(df_min_data, N = n[0], k = K_used) \n",
    "        ad_syn_smote = adaptive_smote.over_sampling()\n",
    "        inspection_smote_data = inspection_classifier(maj_x, maj_y, df_min_data, ad_syn_smote, 0.75)\n",
    "        df_syn1 = pd.DataFrame(inspection_smote_data)\n",
    "        ########################################################## IMPLEMENTATION ##########################################################################\n",
    "\n",
    "        df_syn = df_syn1.sample(n = math.ceil(n[1]*len(df_maj_x)) - len(df_min_data), replace = False, random_state = 0) ####\n",
    "        y_adapt_syn = pd.Series([1 for i in range(len(df_syn))])\n",
    "        new_cols = {x: y for x, y in zip(df_syn, X_4.columns)}\n",
    "        df_min_x = df_min_data.append(df_syn.rename(columns=new_cols)) ###\n",
    "        df_min_y = min_y.append(y_adapt_syn) ###\n",
    "\n",
    "        # add the entire min data with maj data\n",
    "        new_maj_y = pd.Series([0 for i in range(len(df_maj_x))]) ##########\n",
    "        X_train4 = df_maj_x.append(df_min_x.rename(columns=new_cols)) #\n",
    "        y_train4 = new_maj_y.append(df_min_y) ##########\n",
    "        \n",
    "        # Training model\n",
    "        rf_4 = RandomForestClassifier(max_depth = 2, random_state=0)\n",
    "        rf_4.fit(X_train4, y_train4)\n",
    "        y_pred_rf_4 = rf_4.predict(X_test_4)\n",
    "        pr, rc, f_1, auc = score_report_manual(rf_4, X_test_4, y_test_4, y_pred_rf_4)\n",
    "        f1.append(f_1)\n",
    "        precision_lst.append(pr)\n",
    "        recall_lst.append(rc)\n",
    "        auc_lst.append(auc)\n",
    "        len_df_syn.append(len(df_syn))\n",
    "        len_df_maj.append(len(maj_x))\n",
    "        acc = accuracy_score(y_test_4, y_pred_rf_4)\n",
    "        acc_lst.append(acc)\n",
    "        print(f'For fold {fold}:')\n",
    "        print(\"Precision\" , pr)\n",
    "        print(\"Recall\" , rc)\n",
    "        print(\"F1 Score\" ,f_1)\n",
    "        print(\"Accuracy\", acc)\n",
    "      print('average_precision', sum(precision_lst)/5)\n",
    "      print('average_recall', sum(recall_lst)/5)\n",
    "      print('average_f1', sum(f1)/5)\n",
    "      print('average_auc', sum(auc_lst)/5)\n",
    "      print('average_accuracy', sum(acc_lst)/5)\n",
    "      print('stdev_pr', statistics.stdev(precision_lst))\n",
    "      print('stdev_rc', statistics.stdev(recall_lst))\n",
    "      print('stdev_f1', statistics.stdev(f1))\n",
    "      print('stdev_acc', statistics.stdev(acc_lst))\n",
    "      print('--------------------------------------------------')\n",
    "    print('************************************************************')  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
